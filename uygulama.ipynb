{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3LYiWom2MlV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import glob\n",
    "import cv2\n",
    "from torchvision.transforms import ToTensor, Resize\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plcs57KcCCfT",
    "outputId": "2670669b-0cd4-4113-ad8c-b5ba90c1aa32"
   },
   "outputs": [],
   "source": [
    "# Veri Kümesinin indirilmesi\n",
    "#!git clone https://github.com/ardamavi/Sign-Language-Digits-Dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qtp8m-XYGjpR"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, train):\n",
    "        # Veri kümesinin yolu\n",
    "        data_path = \"dataset\"\n",
    "\n",
    "        # Veri kümesine ait klasördeki her bir JPG uzantılı resmin dosya yolu bir listeye kaydedildi.\n",
    "        self.data_list = glob.glob(data_path + \"/*/*.JPG\")\n",
    "\n",
    "        # Liste karıştırıldı.\n",
    "        random.shuffle(self.data_list)\n",
    "\n",
    "        # train True ise eğitim\n",
    "        # train False ise doğrulama verim kümesi olacak şekilde ayarlandı.\n",
    "        if train == True:\n",
    "            self.data_list = self.data_list[:1600]\n",
    "        else:\n",
    "            self.data_list = self.data_list[1600:]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # görüntü dosyadan okunur.\n",
    "        image = cv2.imread(self.data_list[index])\n",
    "\n",
    "        # görüntü pytorch tensor veri tipine dönüştürülür ve 64x64 boyutuna indirgenir\n",
    "        image = ToTensor()(image)\n",
    "        image = Resize((64,64))(image)\n",
    "\n",
    "        # dosya yolu bilgisinden etiket değeri elde edilir.\n",
    "        label = self.data_list[index].split('\\\\')[1]\n",
    "        return image, int(label)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vt-U7SOIMWJd"
   },
   "outputs": [],
   "source": [
    "ds_train = MyDataset(train = True)\n",
    "ds_val = MyDataset(train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DPITRTAJ1-F"
   },
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train,batch_size=32,shuffle=True)\n",
    "dl_val = DataLoader(ds_val,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-09N38n8LYrM"
   },
   "outputs": [],
   "source": [
    "# Konvolüsyonel (evrişimli) bir sinir ağı tasarlandı.\n",
    "# Bir katmanın çıktı sayısı diğer katman için girdi sayısı olacak.\n",
    "# Resmimiz 3 kanaldan oluştuğu için ilk conv_layer'ın in_channels parametresi 3 olarak ayarlandı.\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3,padding=1)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3,padding=1)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,padding=1)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        # Her pooling katmanında resim yarı boyutuna düşer. 2 pooling katmanı kullandık.\n",
    "        # 64x64'lık resim -> 16x16'ya dönüşür.\n",
    "        # full connected layer'ın girdi sayısı : 16x16x64 = 16384 olarak hesaplanır. Buradaki 64 son conv_layer'ın çıktı sayısıdır.\n",
    "        self.fc1 = nn.Linear(16384, 1024)\n",
    "\n",
    "        # Tahmin edilen sınıf sayısı 10 olduğu için modelin çıktı sayısı 10 olarak ayarlandı.\n",
    "        self.fc2 = nn.Linear(1024, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x verisi ilk katmanına girdi olarak verildikten sonra,\n",
    "        # her bir katmanın çıktısı bir sonraki katmanın girdisi olarak ayarlandı.\n",
    "        out = self.conv_layer1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.max_pool1(out)\n",
    "        \n",
    "        out = self.conv_layer3(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.max_pool2(out)\n",
    "                \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pwt5Va88V-eR"
   },
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMMG6beOYT-1"
   },
   "outputs": [],
   "source": [
    "# model cpu'dan gpu'ya aktarılır.\n",
    "\n",
    "#model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQTFQeDbY1He"
   },
   "outputs": [],
   "source": [
    "# kayıp fonksiyonu\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimize edici olarak stochastic gradient descent seçtik, parametre olarak \n",
    "# model parametrelerini ve öğrenme oranını alır\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fDLVHZ-p0a3"
   },
   "outputs": [],
   "source": [
    "# Modeli test etmek için eğitimde kullanılmayan verilerle oluşturduğumuz\n",
    "# dl_val kullanılarak modelin testi gerçekleştirildi. \n",
    "# dogrulama() fonksiyonu çağrıldığında modelin test doğruluğunu verecektir.\n",
    "\n",
    "def dogrulama():\n",
    "    correct = 0\n",
    "    with torch.no_grad():  # İleri yayılımda gradyanların hesaplanmaması için kullanılır. Gradyan hesabı eğitim için gerekli. gradyan hesabının yapılmaması için test aşamasında bu yapıyı kullanıyoruz.\n",
    "        for data, label in dl_val:\n",
    "            tahmin = model(data)   # görüntüler modelden geçirilir ve tahmin değerleri elde edilir.\n",
    "            correct += (tahmin.argmax(1) == label).type(torch.float).sum().item()  # kaç tahmin doğru olarak bulundu\n",
    "\n",
    "    sonuc = correct / len(ds_val)  # doğru olarak bulunan tahminlerin toplam veri sayısına oranı\n",
    "    return sonuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8IIUVbiXO34",
    "outputId": "779b51b0-d50e-4855-830a-56514b205a4c"
   },
   "outputs": [],
   "source": [
    "epoch = 50\n",
    "\n",
    "for idx in range(epoch):\n",
    "    for data, label in dl_train:\n",
    "\n",
    "        # her iterasyonda batch_size miktarınca görüntü modelden geçirilerek her \n",
    "        # görüntü için tahmin değerleri hesaplanıyor.\n",
    "        tahmin = model(data)\n",
    "\n",
    "        # elde edilen tahmin değerlerinin olması gereken değerlerden ne kadar uzak \n",
    "        # olduğuna dair kayıp hesaplanıyor.\n",
    "        loss = loss_fn(tahmin, label)\n",
    "\n",
    "        # Backpropagation (geri yayılım ve ağırlıkların güncellenmesi )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Her epoch'ta kullanıcı bilgilendiriliyor.\n",
    "    print(\"Epoch :\",idx, \"Loss :\", loss.item(), \"val acc\", dogrulama())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsN8AsOCYIVq"
   },
   "outputs": [],
   "source": [
    "# Eğittiğimiz modelin ağırlıklarını diske kaydediyoruz.\n",
    "\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77vRE49_aTHo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acgDbuBuaqMo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled6.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "cdde8dec45b4ce1eca026569354e727deaa3aba8d17b734b4cbbe245da34f1fc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
